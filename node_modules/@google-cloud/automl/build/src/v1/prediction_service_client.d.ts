import * as gax from 'google-gax';
import { Callback, CallOptions, Descriptors, ClientOptions, LROperation } from 'google-gax';
import * as protos from '../../protos/protos';
/**
 *  AutoML Prediction API.
 *
 *  On any input that is documented to expect a string parameter in
 *  snake_case or dash-case, either of those cases is accepted.
 * @class
 * @memberof v1
 */
export declare class PredictionServiceClient {
    private _terminated;
    private _opts;
    private _providedCustomServicePath;
    private _gaxModule;
    private _gaxGrpc;
    private _protos;
    private _defaults;
    auth: gax.GoogleAuth;
    descriptors: Descriptors;
    warn: (code: string, message: string, warnType?: string) => void;
    innerApiCalls: {
        [name: string]: Function;
    };
    pathTemplates: {
        [name: string]: gax.PathTemplate;
    };
    operationsClient: gax.OperationsClient;
    predictionServiceStub?: Promise<{
        [name: string]: Function;
    }>;
    /**
     * Construct an instance of PredictionServiceClient.
     *
     * @param {object} [options] - The configuration object.
     * The options accepted by the constructor are described in detail
     * in [this document](https://github.com/googleapis/gax-nodejs/blob/master/client-libraries.md#creating-the-client-instance).
     * The common options are:
     * @param {object} [options.credentials] - Credentials object.
     * @param {string} [options.credentials.client_email]
     * @param {string} [options.credentials.private_key]
     * @param {string} [options.email] - Account email address. Required when
     *     using a .pem or .p12 keyFilename.
     * @param {string} [options.keyFilename] - Full path to the a .json, .pem, or
     *     .p12 key downloaded from the Google Developers Console. If you provide
     *     a path to a JSON file, the projectId option below is not necessary.
     *     NOTE: .pem and .p12 require you to specify options.email as well.
     * @param {number} [options.port] - The port on which to connect to
     *     the remote host.
     * @param {string} [options.projectId] - The project ID from the Google
     *     Developer's Console, e.g. 'grape-spaceship-123'. We will also check
     *     the environment variable GCLOUD_PROJECT for your project ID. If your
     *     app is running in an environment which supports
     *     {@link https://developers.google.com/identity/protocols/application-default-credentials Application Default Credentials},
     *     your project ID will be detected automatically.
     * @param {string} [options.apiEndpoint] - The domain name of the
     *     API remote host.
     * @param {gax.ClientConfig} [options.clientConfig] - Client configuration override.
     *     Follows the structure of {@link gapicConfig}.
     * @param {boolean} [options.fallback] - Use HTTP fallback mode.
     *     In fallback mode, a special browser-compatible transport implementation is used
     *     instead of gRPC transport. In browser context (if the `window` object is defined)
     *     the fallback mode is enabled automatically; set `options.fallback` to `false`
     *     if you need to override this behavior.
     */
    constructor(opts?: ClientOptions);
    /**
     * Initialize the client.
     * Performs asynchronous operations (such as authentication) and prepares the client.
     * This function will be called automatically when any class method is called for the
     * first time, but if you need to initialize it before calling an actual method,
     * feel free to call initialize() directly.
     *
     * You can await on this method if you want to make sure the client is initialized.
     *
     * @returns {Promise} A promise that resolves to an authenticated service stub.
     */
    initialize(): Promise<{
        [name: string]: Function;
    }>;
    /**
     * The DNS address for this API service.
     * @returns {string} The DNS address for this service.
     */
    static get servicePath(): string;
    /**
     * The DNS address for this API service - same as servicePath(),
     * exists for compatibility reasons.
     * @returns {string} The DNS address for this service.
     */
    static get apiEndpoint(): string;
    /**
     * The port for this API service.
     * @returns {number} The default port for this service.
     */
    static get port(): number;
    /**
     * The scopes needed to make gRPC calls for every method defined
     * in this service.
     * @returns {string[]} List of default scopes.
     */
    static get scopes(): string[];
    getProjectId(): Promise<string>;
    getProjectId(callback: Callback<string, undefined, undefined>): void;
    /**
     * Perform an online prediction. The prediction result is directly
     * returned in the response.
     * Available for following ML scenarios, and their expected request payloads:
     *
     * AutoML Vision Classification
     *
     * * An image in .JPEG, .GIF or .PNG format, image_bytes up to 30MB.
     *
     * AutoML Vision Object Detection
     *
     * * An image in .JPEG, .GIF or .PNG format, image_bytes up to 30MB.
     *
     * AutoML Natural Language Classification
     *
     * * A TextSnippet up to 60,000 characters, UTF-8 encoded or a document in
     * .PDF, .TIF or .TIFF format with size upto 2MB.
     *
     * AutoML Natural Language Entity Extraction
     *
     * * A TextSnippet up to 10,000 characters, UTF-8 NFC encoded or a document
     *  in .PDF, .TIF or .TIFF format with size upto 20MB.
     *
     * AutoML Natural Language Sentiment Analysis
     *
     * * A TextSnippet up to 60,000 characters, UTF-8 encoded or a document in
     * .PDF, .TIF or .TIFF format with size upto 2MB.
     *
     * AutoML Translation
     *
     * * A TextSnippet up to 25,000 characters, UTF-8 encoded.
     *
     * AutoML Tables
     *
     * * A row with column values matching
     *   the columns of the model, up to 5MB. Not available for FORECASTING
     *   `prediction_type`.
     *
     * @param {Object} request
     *   The request object that will be sent.
     * @param {string} request.name
     *   Required. Name of the model requested to serve the prediction.
     * @param {google.cloud.automl.v1.ExamplePayload} request.payload
     *   Required. Payload to perform a prediction on. The payload must match the
     *   problem type that the model was trained to solve.
     * @param {number[]} request.params
     *   Additional domain-specific parameters, any string must be up to 25000
     *   characters long.
     *
     *   AutoML Vision Classification
     *
     *   `score_threshold`
     *   : (float) A value from 0.0 to 1.0. When the model
     *     makes predictions for an image, it will only produce results that have
     *     at least this confidence score. The default is 0.5.
     *
     *   AutoML Vision Object Detection
     *
     *   `score_threshold`
     *   : (float) When Model detects objects on the image,
     *     it will only produce bounding boxes which have at least this
     *     confidence score. Value in 0 to 1 range, default is 0.5.
     *
     *   `max_bounding_box_count`
     *   : (int64) The maximum number of bounding
     *     boxes returned. The default is 100. The
     *     number of returned bounding boxes might be limited by the server.
     *
     *   AutoML Tables
     *
     *   `feature_importance`
     *   : (boolean) Whether
     *   {@link google.cloud.automl.v1.TablesModelColumnInfo.feature_importance|feature_importance}
     *     is populated in the returned list of
     *     {@link google.cloud.automl.v1.TablesAnnotation|TablesAnnotation}
     *     objects. The default is false.
     * @param {object} [options]
     *   Call options. See {@link https://googleapis.dev/nodejs/google-gax/latest/interfaces/CallOptions.html|CallOptions} for more details.
     * @returns {Promise} - The promise which resolves to an array.
     *   The first element of the array is an object representing [PredictResponse]{@link google.cloud.automl.v1.PredictResponse}.
     *   Please see the
     *   [documentation](https://github.com/googleapis/gax-nodejs/blob/master/client-libraries.md#regular-methods)
     *   for more details and examples.
     * @example <caption>include:samples/generated/v1/prediction_service.predict.js</caption>
     * region_tag:automl_v1_generated_PredictionService_Predict_async
     */
    predict(request?: protos.google.cloud.automl.v1.IPredictRequest, options?: CallOptions): Promise<[
        protos.google.cloud.automl.v1.IPredictResponse,
        protos.google.cloud.automl.v1.IPredictRequest | undefined,
        {} | undefined
    ]>;
    predict(request: protos.google.cloud.automl.v1.IPredictRequest, options: CallOptions, callback: Callback<protos.google.cloud.automl.v1.IPredictResponse, protos.google.cloud.automl.v1.IPredictRequest | null | undefined, {} | null | undefined>): void;
    predict(request: protos.google.cloud.automl.v1.IPredictRequest, callback: Callback<protos.google.cloud.automl.v1.IPredictResponse, protos.google.cloud.automl.v1.IPredictRequest | null | undefined, {} | null | undefined>): void;
    /**
     * Perform a batch prediction. Unlike the online {@link google.cloud.automl.v1.PredictionService.Predict|Predict}, batch
     * prediction result won't be immediately available in the response. Instead,
     * a long running operation object is returned. User can poll the operation
     * result via {@link google.longrunning.Operations.GetOperation|GetOperation}
     * method. Once the operation is done, {@link google.cloud.automl.v1.BatchPredictResult|BatchPredictResult} is returned in
     * the {@link google.longrunning.Operation.response|response} field.
     * Available for following ML scenarios:
     *
     * * AutoML Vision Classification
     * * AutoML Vision Object Detection
     * * AutoML Video Intelligence Classification
     * * AutoML Video Intelligence Object Tracking * AutoML Natural Language Classification
     * * AutoML Natural Language Entity Extraction
     * * AutoML Natural Language Sentiment Analysis
     * * AutoML Tables
     *
     * @param {Object} request
     *   The request object that will be sent.
     * @param {string} request.name
     *   Required. Name of the model requested to serve the batch prediction.
     * @param {google.cloud.automl.v1.BatchPredictInputConfig} request.inputConfig
     *   Required. The input configuration for batch prediction.
     * @param {google.cloud.automl.v1.BatchPredictOutputConfig} request.outputConfig
     *   Required. The Configuration specifying where output predictions should
     *   be written.
     * @param {number[]} request.params
     *   Additional domain-specific parameters for the predictions, any string must
     *   be up to 25000 characters long.
     *
     *   AutoML Natural Language Classification
     *
     *   `score_threshold`
     *   : (float) A value from 0.0 to 1.0. When the model
     *     makes predictions for a text snippet, it will only produce results
     *     that have at least this confidence score. The default is 0.5.
     *
     *
     *   AutoML Vision Classification
     *
     *   `score_threshold`
     *   : (float) A value from 0.0 to 1.0. When the model
     *     makes predictions for an image, it will only produce results that
     *     have at least this confidence score. The default is 0.5.
     *
     *   AutoML Vision Object Detection
     *
     *   `score_threshold`
     *   : (float) When Model detects objects on the image,
     *     it will only produce bounding boxes which have at least this
     *     confidence score. Value in 0 to 1 range, default is 0.5.
     *
     *   `max_bounding_box_count`
     *   : (int64) The maximum number of bounding
     *     boxes returned per image. The default is 100, the
     *     number of bounding boxes returned might be limited by the server.
     *   AutoML Video Intelligence Classification
     *
     *   `score_threshold`
     *   : (float) A value from 0.0 to 1.0. When the model
     *     makes predictions for a video, it will only produce results that
     *     have at least this confidence score. The default is 0.5.
     *
     *   `segment_classification`
     *   : (boolean) Set to true to request
     *     segment-level classification. AutoML Video Intelligence returns
     *     labels and their confidence scores for the entire segment of the
     *     video that user specified in the request configuration.
     *     The default is true.
     *
     *   `shot_classification`
     *   : (boolean) Set to true to request shot-level
     *     classification. AutoML Video Intelligence determines the boundaries
     *     for each camera shot in the entire segment of the video that user
     *     specified in the request configuration. AutoML Video Intelligence
     *     then returns labels and their confidence scores for each detected
     *     shot, along with the start and end time of the shot.
     *     The default is false.
     *
     *     WARNING: Model evaluation is not done for this classification type,
     *     the quality of it depends on training data, but there are no metrics
     *     provided to describe that quality.
     *
     *   `1s_interval_classification`
     *   : (boolean) Set to true to request
     *     classification for a video at one-second intervals. AutoML Video
     *     Intelligence returns labels and their confidence scores for each
     *     second of the entire segment of the video that user specified in the
     *     request configuration. The default is false.
     *
     *     WARNING: Model evaluation is not done for this classification
     *     type, the quality of it depends on training data, but there are no
     *     metrics provided to describe that quality.
     *
     *   AutoML Video Intelligence Object Tracking
     *
     *   `score_threshold`
     *   : (float) When Model detects objects on video frames,
     *     it will only produce bounding boxes which have at least this
     *     confidence score. Value in 0 to 1 range, default is 0.5.
     *
     *   `max_bounding_box_count`
     *   : (int64) The maximum number of bounding
     *     boxes returned per image. The default is 100, the
     *     number of bounding boxes returned might be limited by the server.
     *
     *   `min_bounding_box_size`
     *   : (float) Only bounding boxes with shortest edge
     *     at least that long as a relative value of video frame size are
     *     returned. Value in 0 to 1 range. Default is 0.
     *
     * @param {object} [options]
     *   Call options. See {@link https://googleapis.dev/nodejs/google-gax/latest/interfaces/CallOptions.html|CallOptions} for more details.
     * @returns {Promise} - The promise which resolves to an array.
     *   The first element of the array is an object representing
     *   a long running operation. Its `promise()` method returns a promise
     *   you can `await` for.
     *   Please see the
     *   [documentation](https://github.com/googleapis/gax-nodejs/blob/master/client-libraries.md#long-running-operations)
     *   for more details and examples.
     * @example <caption>include:samples/generated/v1/prediction_service.batch_predict.js</caption>
     * region_tag:automl_v1_generated_PredictionService_BatchPredict_async
     */
    batchPredict(request?: protos.google.cloud.automl.v1.IBatchPredictRequest, options?: CallOptions): Promise<[
        LROperation<protos.google.cloud.automl.v1.IBatchPredictResult, protos.google.cloud.automl.v1.IOperationMetadata>,
        protos.google.longrunning.IOperation | undefined,
        {} | undefined
    ]>;
    batchPredict(request: protos.google.cloud.automl.v1.IBatchPredictRequest, options: CallOptions, callback: Callback<LROperation<protos.google.cloud.automl.v1.IBatchPredictResult, protos.google.cloud.automl.v1.IOperationMetadata>, protos.google.longrunning.IOperation | null | undefined, {} | null | undefined>): void;
    batchPredict(request: protos.google.cloud.automl.v1.IBatchPredictRequest, callback: Callback<LROperation<protos.google.cloud.automl.v1.IBatchPredictResult, protos.google.cloud.automl.v1.IOperationMetadata>, protos.google.longrunning.IOperation | null | undefined, {} | null | undefined>): void;
    /**
     * Check the status of the long running operation returned by `batchPredict()`.
     * @param {String} name
     *   The operation name that will be passed.
     * @returns {Promise} - The promise which resolves to an object.
     *   The decoded operation object has result and metadata field to get information from.
     *   Please see the
     *   [documentation](https://github.com/googleapis/gax-nodejs/blob/master/client-libraries.md#long-running-operations)
     *   for more details and examples.
     * @example <caption>include:samples/generated/v1/prediction_service.batch_predict.js</caption>
     * region_tag:automl_v1_generated_PredictionService_BatchPredict_async
     */
    checkBatchPredictProgress(name: string): Promise<LROperation<protos.google.cloud.automl.v1.BatchPredictResult, protos.google.cloud.automl.v1.OperationMetadata>>;
    /**
     * Return a fully-qualified annotationSpec resource name string.
     *
     * @param {string} project
     * @param {string} location
     * @param {string} dataset
     * @param {string} annotation_spec
     * @returns {string} Resource name string.
     */
    annotationSpecPath(project: string, location: string, dataset: string, annotationSpec: string): string;
    /**
     * Parse the project from AnnotationSpec resource.
     *
     * @param {string} annotationSpecName
     *   A fully-qualified path representing AnnotationSpec resource.
     * @returns {string} A string representing the project.
     */
    matchProjectFromAnnotationSpecName(annotationSpecName: string): string | number;
    /**
     * Parse the location from AnnotationSpec resource.
     *
     * @param {string} annotationSpecName
     *   A fully-qualified path representing AnnotationSpec resource.
     * @returns {string} A string representing the location.
     */
    matchLocationFromAnnotationSpecName(annotationSpecName: string): string | number;
    /**
     * Parse the dataset from AnnotationSpec resource.
     *
     * @param {string} annotationSpecName
     *   A fully-qualified path representing AnnotationSpec resource.
     * @returns {string} A string representing the dataset.
     */
    matchDatasetFromAnnotationSpecName(annotationSpecName: string): string | number;
    /**
     * Parse the annotation_spec from AnnotationSpec resource.
     *
     * @param {string} annotationSpecName
     *   A fully-qualified path representing AnnotationSpec resource.
     * @returns {string} A string representing the annotation_spec.
     */
    matchAnnotationSpecFromAnnotationSpecName(annotationSpecName: string): string | number;
    /**
     * Return a fully-qualified dataset resource name string.
     *
     * @param {string} project
     * @param {string} location
     * @param {string} dataset
     * @returns {string} Resource name string.
     */
    datasetPath(project: string, location: string, dataset: string): string;
    /**
     * Parse the project from Dataset resource.
     *
     * @param {string} datasetName
     *   A fully-qualified path representing Dataset resource.
     * @returns {string} A string representing the project.
     */
    matchProjectFromDatasetName(datasetName: string): string | number;
    /**
     * Parse the location from Dataset resource.
     *
     * @param {string} datasetName
     *   A fully-qualified path representing Dataset resource.
     * @returns {string} A string representing the location.
     */
    matchLocationFromDatasetName(datasetName: string): string | number;
    /**
     * Parse the dataset from Dataset resource.
     *
     * @param {string} datasetName
     *   A fully-qualified path representing Dataset resource.
     * @returns {string} A string representing the dataset.
     */
    matchDatasetFromDatasetName(datasetName: string): string | number;
    /**
     * Return a fully-qualified model resource name string.
     *
     * @param {string} project
     * @param {string} location
     * @param {string} model
     * @returns {string} Resource name string.
     */
    modelPath(project: string, location: string, model: string): string;
    /**
     * Parse the project from Model resource.
     *
     * @param {string} modelName
     *   A fully-qualified path representing Model resource.
     * @returns {string} A string representing the project.
     */
    matchProjectFromModelName(modelName: string): string | number;
    /**
     * Parse the location from Model resource.
     *
     * @param {string} modelName
     *   A fully-qualified path representing Model resource.
     * @returns {string} A string representing the location.
     */
    matchLocationFromModelName(modelName: string): string | number;
    /**
     * Parse the model from Model resource.
     *
     * @param {string} modelName
     *   A fully-qualified path representing Model resource.
     * @returns {string} A string representing the model.
     */
    matchModelFromModelName(modelName: string): string | number;
    /**
     * Return a fully-qualified modelEvaluation resource name string.
     *
     * @param {string} project
     * @param {string} location
     * @param {string} model
     * @param {string} model_evaluation
     * @returns {string} Resource name string.
     */
    modelEvaluationPath(project: string, location: string, model: string, modelEvaluation: string): string;
    /**
     * Parse the project from ModelEvaluation resource.
     *
     * @param {string} modelEvaluationName
     *   A fully-qualified path representing ModelEvaluation resource.
     * @returns {string} A string representing the project.
     */
    matchProjectFromModelEvaluationName(modelEvaluationName: string): string | number;
    /**
     * Parse the location from ModelEvaluation resource.
     *
     * @param {string} modelEvaluationName
     *   A fully-qualified path representing ModelEvaluation resource.
     * @returns {string} A string representing the location.
     */
    matchLocationFromModelEvaluationName(modelEvaluationName: string): string | number;
    /**
     * Parse the model from ModelEvaluation resource.
     *
     * @param {string} modelEvaluationName
     *   A fully-qualified path representing ModelEvaluation resource.
     * @returns {string} A string representing the model.
     */
    matchModelFromModelEvaluationName(modelEvaluationName: string): string | number;
    /**
     * Parse the model_evaluation from ModelEvaluation resource.
     *
     * @param {string} modelEvaluationName
     *   A fully-qualified path representing ModelEvaluation resource.
     * @returns {string} A string representing the model_evaluation.
     */
    matchModelEvaluationFromModelEvaluationName(modelEvaluationName: string): string | number;
    /**
     * Terminate the gRPC channel and close the client.
     *
     * The client will no longer be usable and all future behavior is undefined.
     * @returns {Promise} A promise that resolves when the client is closed.
     */
    close(): Promise<void>;
}
